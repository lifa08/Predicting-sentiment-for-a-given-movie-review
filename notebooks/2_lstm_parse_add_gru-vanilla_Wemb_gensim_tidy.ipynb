{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: integrate the word2vect to the first method\n",
    "\n",
    "Training can take 6 hours or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"../img/Method2/LSTM_Wordembedding.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import six.moves.cPickle as pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import theano\n",
    "from theano import config\n",
    "import theano.tensor as tensor\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "sys.path.append('../script')\n",
    "import imdb\n",
    "import Wemb_gensim\n",
    "\n",
    "import pickle as pkl\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = {'imdb': (imdb.load_data, imdb.prepare_data)}\n",
    "SEED = 123\n",
    "numpy.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adadelta(lr, tparams, grads, x, mask, y, cost):\n",
    "    \"\"\"\n",
    "    An adaptive learning rate optimizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : Theano SharedVariable\n",
    "        Initial learning rate\n",
    "    tpramas: Theano SharedVariable\n",
    "        Model parameters\n",
    "    grads: Theano variable\n",
    "        Gradients of cost w.r.t to parameres\n",
    "    x: Theano variable\n",
    "        Model inputs\n",
    "    mask: Theano variable\n",
    "        Sequence mask\n",
    "    y: Theano variable\n",
    "        Targets\n",
    "    cost: Theano variable\n",
    "        Objective fucntion to minimize\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For more information, see [ADADELTA]_.\n",
    "\n",
    "    .. [ADADELTA] Matthew D. Zeiler, *ADADELTA: An Adaptive Learning\n",
    "       Rate Method*, arXiv:1212.5701.\n",
    "    \"\"\"\n",
    "\n",
    "    zipped_grads = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                  name='%s_grad' % k)\n",
    "                    for k, p in tparams.items()]\n",
    "    running_up2 = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                 name='%s_rup2' % k)\n",
    "                   for k, p in tparams.items()]\n",
    "    running_grads2 = [theano.shared(p.get_value() * numpy_floatX(0.),\n",
    "                                    name='%s_rgrad2' % k)\n",
    "                      for k, p in tparams.items()]\n",
    "\n",
    "    zgup = [(zg, g) for zg, g in zip(zipped_grads, grads)]\n",
    "    rg2up = [(rg2, 0.95 * rg2 + 0.05 * (g ** 2))\n",
    "             for rg2, g in zip(running_grads2, grads)]\n",
    "\n",
    "    f_grad_shared = theano.function([x, mask, y], cost, updates=zgup + rg2up,\n",
    "                                    name='adadelta_f_grad_shared')\n",
    "\n",
    "    updir = [-tensor.sqrt(ru2 + 1e-6) / tensor.sqrt(rg2 + 1e-6) * zg\n",
    "             for zg, ru2, rg2 in zip(zipped_grads,\n",
    "                                     running_up2,\n",
    "                                     running_grads2)]\n",
    "    ru2up = [(ru2, 0.95 * ru2 + 0.05 * (ud ** 2))\n",
    "             for ru2, ud in zip(running_up2, updir)]\n",
    "    param_up = [(p, p + ud) for p, ud in zip(tparams.values(), updir)]\n",
    "\n",
    "    f_update = theano.function([lr], [], updates=ru2up + param_up,\n",
    "                               on_unused_input='ignore',\n",
    "                               name='adadelta_f_update')\n",
    "\n",
    "    return f_grad_shared, f_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ortho_weight(ndim):\n",
    "    W = numpy.random.randn(ndim, ndim)\n",
    "    u, s, v = numpy.linalg.svd(W)\n",
    "    return u.astype(config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _p(pp, name):\n",
    "    return '%s_%s' % (pp, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the parameters of lstm layer\n",
    "def param_init_lstm(options, params, prefix='lstm'):\n",
    "    \"\"\"\n",
    "    Init the LSTM parameter:\n",
    "\n",
    "    :see: init_params\n",
    "    \"\"\"\n",
    "    W = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'W')] = W # _p is a function to concate prefix and W --> lstm_W\n",
    "    U = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'U')] = U\n",
    "    b = numpy.zeros((4 * options['dim_proj'],))\n",
    "    params[_p(prefix, 'b')] = b.astype(config.floatX)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state_below is passed in the emb --> the weights in the first layer ? why not X\n",
    "# because emb is the embedding of words which represents words\n",
    "def lstm_layer(tparams, state_below, options, prefix='lstm', mask=None):\n",
    "    nsteps = state_below.shape[0] # time steps namely, the number of words in a sentence\n",
    "    if state_below.ndim == 3:\n",
    "        n_samples = state_below.shape[1] # the number of sentences in a minibatch\n",
    "    else:\n",
    "        n_samples = 1 # in the case of no minibach applied, then train with one sentence at a time\n",
    "\n",
    "    assert mask is not None # sequence mask must be provided\n",
    "\n",
    "    def _slice(_x, n, dim):\n",
    "        if _x.ndim == 3:\n",
    "            return _x[:, :, n * dim:(n + 1) * dim]\n",
    "        return _x[:, n * dim:(n + 1) * dim]\n",
    "\n",
    "    # m_: mask, x_: state_below which is emb * lstm_W + lstm_b\n",
    "    def _step(m_, x_, h_, c_):\n",
    "        preact = tensor.dot(h_, tparams[_p(prefix, 'U')]) # lstm_U*h_t-1\n",
    "        preact += x_ # Wemb * lstm_W + lstm_b + lstm_U*h_t-1\n",
    "\n",
    "        i = tensor.nnet.sigmoid(_slice(preact, 0, options['dim_proj']))\n",
    "        f = tensor.nnet.sigmoid(_slice(preact, 1, options['dim_proj']))\n",
    "        o = tensor.nnet.sigmoid(_slice(preact, 2, options['dim_proj']))\n",
    "        c = tensor.tanh(_slice(preact, 3, options['dim_proj']))\n",
    "\n",
    "        c = f * c_ + i * c # c_ means previous state refer to s[t]= f*s[t-1] + i*s[t]\n",
    "        c = m_[:, None] * c + (1. - m_)[:, None] * c_ # c is of shape (minibatch maxlen, number of sentences\n",
    "                                                    # in a minibatch, word embbdeding size) = (98, 16, 4)\n",
    "        # c = theano.printing.Print('c')(c)\n",
    "\n",
    "        h = o * tensor.tanh(c)\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h, c\n",
    "\n",
    "    # emb * lstm_W + lstm_b\n",
    "    state_below = (tensor.dot(state_below, tparams[_p(prefix, 'W')]) +\n",
    "                   tparams[_p(prefix, 'b')])\n",
    "\n",
    "    dim_proj = options['dim_proj']\n",
    "    # scan function, sequence is the input x, nonsequence is ussually not iterated such as w and b\n",
    "    rval, updates = theano.scan(_step,\n",
    "                                sequences=[mask, state_below],\n",
    "                                outputs_info=[tensor.alloc(numpy_floatX(0.),\n",
    "                                                           n_samples,\n",
    "                                                           dim_proj),\n",
    "                                              tensor.alloc(numpy_floatX(0.),\n",
    "                                                           n_samples,\n",
    "                                                           dim_proj)],\n",
    "                                name=_p(prefix, '_layers'),\n",
    "                                n_steps=nsteps) # repeat as the number of words in a sentence\n",
    "    return rval[0] # rval = h which is of shape (n_samples, dim_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gru_layer(tparams, state_below, options, prefix='gru', mask=None):\n",
    "    nsteps = state_below.shape[0]\n",
    "    if state_below.ndim == 3:\n",
    "        n_samples = state_below.shape[1]\n",
    "    else:\n",
    "        n_samples = 1\n",
    "\n",
    "    assert mask is not None\n",
    "\n",
    "    def _slice(_x, n, dim):\n",
    "        if _x.ndim == 3:\n",
    "            return _x[:, :, n * dim:(n + 1) * dim]\n",
    "        return _x[:, n * dim:(n + 1) * dim]\n",
    "    \n",
    "    def x_seperate(_x, dim):\n",
    "        if _x.ndim == 3:\n",
    "            return _x[:, :, 0: 2 * dim], _x[:, :, 2 * dim:]\n",
    "        return _x[:, 0: 2 * dim], _x[:, 2 * dim:]\n",
    "\n",
    "    def _step(m_, x_, h_):\n",
    "        _x12, _x3 = x_seperate(x_, model_options['dim_proj'])\n",
    "\n",
    "        preact = tensor.dot(h_, tparams[_p(prefix, 'U')])\n",
    "        preact += _x12\n",
    "\n",
    "        m = tensor.nnet.sigmoid(preact)\n",
    "        r = _slice(m, 0, model_options['dim_proj'])\n",
    "        u = _slice(m, 1, model_options['dim_proj'])\n",
    "\n",
    "        _h = tensor.tanh(_x3 + tensor.dot(r * h_, tparams[_p(prefix, 'W_hh')]))\n",
    "        h = u * h_ + (1.0 - u) * _h\n",
    "\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "\n",
    "        return h\n",
    "\n",
    "    state_below = (tensor.dot(state_below, tparams[_p(prefix, 'W')]) +\n",
    "                   tparams[_p(prefix, 'b')])\n",
    "\n",
    "    dim_proj = options['dim_proj']\n",
    "    initial_hidden_vector = tensor.alloc(numpy_floatX(0.), n_samples, dim_proj)\n",
    "\n",
    "    rval, updates = theano.scan(_step,\n",
    "                                sequences=[mask, state_below],\n",
    "                                outputs_info=[initial_hidden_vector],\n",
    "                                name=_p(prefix, '_layers'),\n",
    "                                n_steps=nsteps)\n",
    "    return rval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the parameters of gru layer\n",
    "def param_init_gru(options, params, prefix='gru'):\n",
    "    \"\"\"\n",
    "    Init the GRU parameter:\n",
    "\n",
    "    :see: init_params\n",
    "    \"\"\"\n",
    "    W = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'W')] = W\n",
    "        \n",
    "    U = numpy.concatenate([ortho_weight(options['dim_proj']),\n",
    "                           ortho_weight(options['dim_proj'])], axis=1)\n",
    "    params[_p(prefix, 'U')] = U\n",
    "\n",
    "    W_hh = ortho_weight(options['dim_proj'])\n",
    "    params[_p(prefix, 'W_hh')] = W_hh\n",
    "\n",
    "    b = numpy.zeros((3 * options['dim_proj'],))\n",
    "    params[_p(prefix, 'b')] = b.astype(config.floatX)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vanilla_layer(tparams, state_below, options, prefix='vanilla', mask=None):\n",
    "    nsteps = state_below.shape[0]\n",
    "    if state_below.ndim == 3:\n",
    "        n_samples = state_below.shape[1]\n",
    "    else:\n",
    "        n_samples = 1\n",
    "\n",
    "    assert mask is not None\n",
    "\n",
    "    def _step(m_, x_, h_):\n",
    "        a = x_ + tensor.dot(h_, tparams[_p(prefix, 'W')])\n",
    "        h = tensor.tanh(a)\n",
    "        h = m_[:, None] * h + (1. - m_)[:, None] * h_\n",
    "        return h\n",
    "\n",
    "    state_below = (tensor.dot(state_below, tparams[_p(prefix, 'U')]) +\n",
    "                   tparams[_p(prefix, 'b')])\n",
    "\n",
    "    dim_proj = options['dim_proj']\n",
    "    initial_hidden_vector = tensor.alloc(numpy_floatX(0.), n_samples, dim_proj)\n",
    "\n",
    "    rval, updates = theano.scan(_step,\n",
    "                                sequences=[mask, state_below],\n",
    "                                outputs_info=[initial_hidden_vector],\n",
    "                                name=_p(prefix, '_layers'),\n",
    "                                n_steps=nsteps)\n",
    "    return rval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_init_vanilla(options, params, prefix='vanilla'):\n",
    "    \"\"\"\n",
    "    Init the vanilla RNN parameter:\n",
    "\n",
    "    :see: init_params\n",
    "    \"\"\"\n",
    "    ndim = options['dim_proj']\n",
    "    W_bound = numpy.sqrt(6. / (ndim + ndim))\n",
    "\n",
    "    U = numpy.asarray(numpy.random.uniform(low=-W_bound, high=W_bound, size=(ndim, ndim)))\n",
    "    params[_p(prefix, 'U')] = U.astype(config.floatX)\n",
    "    \n",
    "    W = numpy.asarray(numpy.random.uniform(low=-W_bound, high=W_bound, size=(ndim, ndim)))\n",
    "    params[_p(prefix, 'W')] = W.astype(config.floatX)\n",
    "\n",
    "    b = numpy.zeros(options['dim_proj'],)\n",
    "    params[_p(prefix, 'b')] = b.astype(config.floatX)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ff: Feed Forward (normal neural net), only useful to put after lstm\n",
    "#     before the classifier.\n",
    "layers = {'lstm': (param_init_lstm, lstm_layer), \\\n",
    "         'gru': (param_init_gru, gru_layer), \\\n",
    "         'vanilla': (param_init_vanilla, vanilla_layer)}\n",
    "\n",
    "def get_layer(name):\n",
    "    fns = layers[name]\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_params(options):\n",
    "    \"\"\"\n",
    "    Global (not LSTM) parameters. For the embeding and the classifier.\n",
    "    \"\"\"\n",
    "    params = OrderedDict()\n",
    "\n",
    "    # embedding layer\n",
    "    if(options['gensim_Wemb']):\n",
    "        f = open('../data/gensim/gensim_imdb_Wemb.pkl', 'rb')\n",
    "        Wemb = pkl.load(f)\n",
    "        f.close()\n",
    "\n",
    "        params['Wemb'] = (Wemb[:options['n_words']]).astype(config.floatX)\n",
    "        # print(params['Wemb'].shape)\n",
    "        assert params['Wemb'].shape[0] == options['n_words']\n",
    "        assert params['Wemb'].shape[1] == options['dim_proj']\n",
    "    else:\n",
    "        print('wemb random initialization')\n",
    "        randn = numpy.random.rand(options['n_words'],\n",
    "                                  options['dim_proj']) # n_words = vocabulary size, dim_proj = word embedding size\n",
    "        params['Wemb'] = (0.01 * randn).astype(config.floatX)\n",
    "\n",
    "    # lstm layer\n",
    "    params = get_layer(options['encoder'])[0](options, params, prefix=options['encoder'])\n",
    "\n",
    "    # classifier\n",
    "    params['U'] = 0.01 * numpy.random.randn(options['dim_proj'],\n",
    "                                            options['ydim']).astype(config.floatX)\n",
    "    params['b'] = numpy.zeros((options['ydim'],)).astype(config.floatX)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_tparams(params):\n",
    "    tparams = OrderedDict()\n",
    "    for kk, pp in params.items():\n",
    "        tparams[kk] = theano.shared(params[kk], name=kk)\n",
    "    return tparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state_before is proj namely hidden state\n",
    "def dropout_layer(state_before, use_noise, trng):\n",
    "    proj = tensor.switch(use_noise,\n",
    "                         (state_before *\n",
    "                          trng.binomial(state_before.shape,\n",
    "                                        p=0.5, n=1,\n",
    "                                        dtype=state_before.dtype)),\n",
    "                         state_before * 0.5)\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numpy_floatX(data):\n",
    "    return numpy.asarray(data, dtype=config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(tparams, options):\n",
    "    trng = RandomStreams(SEED)\n",
    "\n",
    "    # Used for dropout.\n",
    "    use_noise = theano.shared(numpy_floatX(0.)) # --> [0], thus this line of code is the same as use_noise=[0]\n",
    "\n",
    "    x = tensor.matrix('x', dtype='int64') # x is a sentence with each word form a row?\n",
    "    mask = tensor.matrix('mask', dtype=config.floatX) # sequence mask\n",
    "    y = tensor.vector('y', dtype='int64')\n",
    "\n",
    "    n_timesteps = x.shape[0] # number of words per sentence\n",
    "    n_samples = x.shape[1] # number of sentences in a minibatch\n",
    "\n",
    "    # x.flatten() --> number_timesteps * n_samples\n",
    "    emb = tparams['Wemb'][x.flatten()].reshape([n_timesteps,\n",
    "                                                n_samples,\n",
    "                                                options['dim_proj']]) # each word in the sentence\n",
    "                                                                      # get different weights\n",
    "\n",
    "    # call get_layer(options['encoder'])[1] --> lstm_layer --> lstm_layer(tparams,...,)\n",
    "    # here emb is used to initialize states_below in lstm_layer function\n",
    "    proj = get_layer(options['encoder'])[1](tparams, emb, options,\n",
    "                                            prefix=options['encoder'],\n",
    "                                            mask=mask)\n",
    "\n",
    "    projshape = theano.printing.Print('proj')(proj.shape)\n",
    "    # mean over word hidden representations in a sentence, proj is of shape(n_samples, dim_proj)\n",
    "    if options['encoder'] == 'lstm' or options['encoder'] == 'gru':\n",
    "        proj = (proj * mask[:, :, None]).sum(axis=0) # add up the hidden representations of all words in a sentence\n",
    "        proj = proj / mask.sum(axis=0)[:, None] # mask.sum(axis=0) is the length of sentence without padding\n",
    "    if options['use_dropout']:\n",
    "        proj = dropout_layer(proj, use_noise, trng)\n",
    "\n",
    "    # last layer\n",
    "    pred = tensor.nnet.softmax(tensor.dot(proj, tparams['U']) + tparams['b'])\n",
    "    # pred is the probability of a sentence belonging to a class. It is of shape (n_samples, class)\n",
    "\n",
    "    f_pred_prob = theano.function([x, mask], pred, name='f_pred_prob')\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    if pred.dtype == 'float16':\n",
    "        off = 1e-6\n",
    "\n",
    "    # get the probability of the right class and calculate its negative log. --> negative log likelihood\n",
    "    cost = -tensor.log(pred[tensor.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return use_noise, x, mask, y, f_pred_prob, f_pred, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatches_idx(n, minibatch_size, shuffle=False):\n",
    "    \"\"\"\n",
    "    Used to shuffle the dataset at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    idx_list = numpy.arange(n, dtype=\"int32\")\n",
    "\n",
    "    if shuffle:\n",
    "        numpy.random.shuffle(idx_list)\n",
    "\n",
    "    minibatches = []\n",
    "    minibatch_start = 0\n",
    "    for i in range(n // minibatch_size):\n",
    "        minibatches.append(idx_list[minibatch_start:\n",
    "                                    minibatch_start + minibatch_size])\n",
    "        minibatch_start += minibatch_size\n",
    "\n",
    "    if (minibatch_start != n):\n",
    "        # Make a minibatch out of what is left\n",
    "        minibatches.append(idx_list[minibatch_start:])\n",
    "\n",
    "    return zip(range(len(minibatches)), minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip(zipped):\n",
    "    \"\"\"\n",
    "    When we pickle the model. Needed for the GPU stuff.\n",
    "    \"\"\"\n",
    "    new_params = OrderedDict()\n",
    "    for kk, vv in zipped.items():\n",
    "        new_params[kk] = vv.get_value()\n",
    "    return new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zipp(params, tparams):\n",
    "    \"\"\"\n",
    "    When we reload the model. Needed for the GPU stuff.\n",
    "    \"\"\"\n",
    "    for kk, vv in params.items():\n",
    "        tparams[kk].set_value(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_error(f_pred, prepare_data, data, iterator, verbose=False):\n",
    "    \"\"\"\n",
    "    Just compute the error\n",
    "    f_pred: Theano fct computing the prediction\n",
    "    prepare_data: usual prepare_data for that dataset.\n",
    "    \"\"\"\n",
    "    valid_err = 0\n",
    "    for _, valid_index in iterator:\n",
    "        x, mask, y = prepare_data([data[0][t] for t in valid_index],\n",
    "                                  numpy.array(data[1])[valid_index],\n",
    "                                  maxlen=None)\n",
    "        preds = f_pred(x, mask)\n",
    "        targets = numpy.array(data[1])[valid_index]\n",
    "        valid_err += (preds == targets).sum()\n",
    "    valid_err = 1. - numpy_floatX(valid_err) / len(data[0])\n",
    "\n",
    "    return valid_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    return datasets[name][0], datasets[name][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_costs = numpy.array([]) # add for plot\n",
    "train_accus = numpy.array([])\n",
    "history_errs = []\n",
    "def train_model(\n",
    "    encoder,\n",
    "    gensim_Wemb, # Use gensim word embedding or not\n",
    "    dim_proj=128,  # word embeding dimension and the number of hidden units of LSTM.\n",
    "    patience=10,  # Number of epoch to wait before early stop if no progress\n",
    "    max_epochs=2,  # The maximum number of epoch to run\n",
    "    dispFreq=10,  # Display to stdout the training progress every N updates\n",
    "    decay_c=0.,  # Weight decay for the classifier applied to the U weights.\n",
    "    lrate=0.0001,  # Learning rate for sgd (not used for adadelta and rmsprop)\n",
    "    n_words=100000,  # Vocabulary size actual size is about 114526\n",
    "    optimizer=adadelta,  # sgd, adadelta and rmsprop available, sgd very hard to use, not recommanded\n",
    "    saveto='../trained_models/Method1_and_2/lstm_model.npz',  # The best model will be saved there\n",
    "    validFreq=370,  # Compute the validation error after this number of update.\n",
    "    saveFreq=1110,  # Save the parameters after every saveFreq updates\n",
    "    maxlen=700,  # Sequence longer then this get ignored\n",
    "    batch_size=16,  # The batch size during training.\n",
    "    valid_batch_size=64,  # The batch size used for validation/test set.\n",
    "    dataset='imdb',\n",
    "    gensim_retrain=False, # retrain word2vec or not\n",
    "\n",
    "    # Parameter for extra option\n",
    "    noise_std=0.,\n",
    "    use_dropout=True,  # if False slightly faster, but worst test error\n",
    "                       # This frequently need a bigger model.\n",
    "    reload_model=None,  # Path to a saved model we want to start from.\n",
    "    test_size=-1,  # If >0, we keep only this number of test example.\n",
    "):\n",
    "    global train_costs\n",
    "    global train_accus\n",
    "    global history_errs\n",
    "    model_options = locals().copy()\n",
    "    if gensim_retrain:\n",
    "        path = '../data/aclImdb/'\n",
    "        print('Training gensim word2vec model')\n",
    "        Wemb_gensim.train_gensim_w2vec(path, Wemb_size=dim_proj, w2v_iter=20)\n",
    "\n",
    "    # Get the function names from imdb module\n",
    "    load_data, prepare_data = get_dataset(model_options['dataset'])\n",
    "\n",
    "    print('Loading data')\n",
    "    train, valid, test = load_data(\n",
    "        path='../data/gensim/gensim_imdb.pkl',\n",
    "        n_words=n_words,\n",
    "        valid_portion=0.05)\n",
    "\n",
    "    if test_size > 0:\n",
    "        print(len(test[0]))\n",
    "        idx = numpy.arange(len(test[0])) # test[0] is test_x\n",
    "        numpy.random.shuffle(idx)\n",
    "        idx = idx[:test_size]\n",
    "        test = ([test[0][n] for n in idx], [test[1][n] for n in idx])\n",
    "\n",
    "    # Get the number of sentimental class\n",
    "    ydim = numpy.max(train[1]) + 1 # train_y = train[1]\n",
    "    model_options['ydim'] = ydim\n",
    "\n",
    "    print('Building model')\n",
    "    params = init_params(model_options)\n",
    "\n",
    "    # This create Theano Shared Variable from the parameters.\n",
    "    # Dict name (string) -> Theano Tensor Shared Variable\n",
    "    # params and tparams have different copy of the weights.\n",
    "    tparams = init_tparams(params)\n",
    "\n",
    "    (use_noise, x, mask,\n",
    "     y, f_pred_prob, f_pred, cost) = build_model(tparams, model_options)\n",
    "\n",
    "    # add weight decay\n",
    "    if decay_c > 0.:\n",
    "        decay_c = theano.shared(numpy_floatX(decay_c), name='decay_c')\n",
    "        weight_decay = 0.\n",
    "        weight_decay += (tparams['U'] ** 2).sum()\n",
    "        weight_decay *= decay_c\n",
    "        cost += weight_decay\n",
    "\n",
    "    # define cost that includes weight decay\n",
    "    f_cost = theano.function([x, mask, y], cost, name='f_cost')\n",
    "\n",
    "    # define gradient functions\n",
    "    grads = tensor.grad(cost, wrt=list(tparams.values()))\n",
    "    f_grad = theano.function([x, mask, y], grads, name='f_grad')\n",
    "\n",
    "    # define optmizer\n",
    "    lr = tensor.scalar(name='lr')\n",
    "    f_grad_shared, f_update = optimizer(lr, tparams, grads,\n",
    "                                        x, mask, y, cost)\n",
    "\n",
    "    print('Optimization')\n",
    "    kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "    kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "\n",
    "    print(\"%d train examples\" % len(train[0]))\n",
    "    print(\"%d valid examples\" % len(valid[0]))\n",
    "    print(\"%d test examples\" % len(test[0]))\n",
    "\n",
    "    \n",
    "    best_p = None # for storing best parameters\n",
    "    bad_count = 0\n",
    "\n",
    "    if validFreq == -1:\n",
    "        validFreq = len(train[0]) // batch_size\n",
    "    if saveFreq == -1:\n",
    "        saveFreq = len(train[0]) // batch_size\n",
    "\n",
    "    uidx = 0  # the number of update done\n",
    "    estop = False  # early stop\n",
    "\n",
    "   \n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        for eidx in range(max_epochs):\n",
    "            n_samples = 0 # the number of sentence\n",
    "            \n",
    "            # Get new shuffled index for the training set.\n",
    "            kf = get_minibatches_idx(len(train[0]), batch_size, shuffle=True)\n",
    "            training_set_size = len(kf)\n",
    "            \n",
    "            for _, train_index in kf:\n",
    "                uidx += 1\n",
    "                use_noise.set_value(1.) # going to use noise\n",
    "\n",
    "                # Select the random examples for this minibatch\n",
    "                y = [train[1][t] for t in train_index]\n",
    "                x = [train[0][t] for t in train_index] # wrap 16 sentences into an array \n",
    "                                            # as a result, x is of 2 dimensions, size of 1998/16 * 16 sentences\n",
    "                # Get the data in numpy.ndarray format\n",
    "                # This swap the axis!\n",
    "                # Return something of shape (minibatch maxlen, n samples)\n",
    "                # n_samples is the number of sentences in a minibatch\n",
    "                x, mask, y = prepare_data(x, y) # all the sentence will have the same length which is minibatch maxlen\n",
    "                n_samples += x.shape[1] # x.shape[1] is the number of sentence in a minibatch\n",
    "\n",
    "                cost = f_grad_shared(x, mask, y) # call the model\n",
    "                f_update(lrate)\n",
    "\n",
    "                accuracy = (f_pred(x, mask) == y).sum() / len(y)\n",
    "                train_costs = numpy.append(train_costs, cost)\n",
    "                train_accus = numpy.append(train_accus, accuracy)\n",
    "\n",
    "                if numpy.isnan(cost) or numpy.isinf(cost):\n",
    "                    print('bad cost detected: ', cost)\n",
    "                    break\n",
    "                if numpy.mod(uidx, dispFreq) == 0:\n",
    "                    remainder = (uidx % training_set_size)\n",
    "                    if(remainder == 0 and uidx != 0):\n",
    "                        remainder = training_set_size\n",
    "                    print('Epoch ' + str(eidx + 1) + \"/\" + str(max_epochs) + ' Update ' + str(remainder) + \"/\" + str(training_set_size) + ' Cost ' + str(cost))\n",
    "                    progress = (float(eidx) / float(max_epochs)) + ((float(remainder) / float(training_set_size)) / max_epochs)\n",
    "                    if(progress != 0):\n",
    "                        time_taken = (time.time() - start_time) / 60\n",
    "                        time_remaining = time_taken / progress\n",
    "                        print('Progress: %.1fmin / ' % time_taken + '%.1fmin' % time_remaining + ' (%.0f' % (progress * 100) + \"%)\") \n",
    "\n",
    "                if saveto and numpy.mod(uidx, saveFreq) == 0:\n",
    "                    print('Saving...')\n",
    "\n",
    "                    if best_p is not None:\n",
    "                        params = best_p\n",
    "                    else:\n",
    "                        params = unzip(tparams)\n",
    "                        numpy.savez(saveto, history_errs=history_errs, **params)\n",
    "                        pickle.dump(model_options, open('%s.pkl' % saveto, 'wb'), -1)\n",
    "                        print('Done')\n",
    "                if numpy.mod(uidx, validFreq) == 0:\n",
    "                    print(\"Validating.\")\n",
    "                    use_noise.set_value(0.) # at validation stage, dont use noise\n",
    "                    train_err = pred_error(f_pred, prepare_data, train, kf)\n",
    "                    valid_err = pred_error(f_pred, prepare_data, valid, kf_valid)\n",
    "                    test_err = pred_error(f_pred, prepare_data, test, kf_test)\n",
    "\n",
    "                    kf_valid = get_minibatches_idx(len(valid[0]), valid_batch_size)\n",
    "                    kf_test = get_minibatches_idx(len(test[0]), valid_batch_size)\n",
    "\n",
    "                    history_errs.append([valid_err, test_err])\n",
    "\n",
    "                    if (best_p is None or\n",
    "                        valid_err <= numpy.array(history_errs)[:, 0].min()):\n",
    "\n",
    "                        best_p = unzip(tparams)\n",
    "                        bad_counter = 0\n",
    "\n",
    "                    print('Train ', train_err, 'Valid ', valid_err,\n",
    "                           'Test ', test_err)\n",
    "\n",
    "                    print(\"Testing for early stop criteria.\")\n",
    "                    print(\"1.) len(history_errs)=\" + str(len(history_errs)) + \" > patience=\" + str(patience)+ \"?\")\n",
    "                    if(len(history_errs) > patience):\n",
    "                        print(\"2.) valid_err=\" + str(valid_err) + \" >= numpy.array(history_errs)[:-patience,0].min()=\" + str(numpy.array(history_errs)[:-patience,0].min()) + \"?\")\n",
    "                        if(valid_err >= numpy.array(history_errs)[:-patience,\n",
    "                                                           0].min()):\n",
    "                            print(\"bad_counter=\" + str(bad_counter) + \" > patience=\" + str(patience) + \"?\")\n",
    "                        \n",
    "                    if (len(history_errs) > patience and\n",
    "                        valid_err >= numpy.array(history_errs)[:-patience,\n",
    "                                                               0].min()):\n",
    "                        bad_counter += 1\n",
    "                        if bad_counter > patience:\n",
    "                            print('Early Stop!')\n",
    "                            estop = True\n",
    "                            break\n",
    "\n",
    "            print('Seen %d samples' % n_samples)\n",
    "\n",
    "            if estop:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interupted\")\n",
    "\n",
    "    \n",
    "    print(\"Doing final calculations.\")\n",
    "    \n",
    "    if best_p is not None:\n",
    "        zipp(best_p, tparams)\n",
    "    else:\n",
    "        best_p = unzip(tparams)\n",
    "\n",
    "    use_noise.set_value(0.)\n",
    "    kf_train_sorted = get_minibatches_idx(len(train[0]), batch_size)\n",
    "    train_err = pred_error(f_pred, prepare_data, train, kf_train_sorted)\n",
    "    valid_err = pred_error(f_pred, prepare_data, valid, kf_valid)\n",
    "    test_err = pred_error(f_pred, prepare_data, test, kf_test)\n",
    "\n",
    "    print( 'Train ', train_err, 'Valid ', valid_err, 'Test ', test_err )\n",
    "    if saveto:\n",
    "        numpy.savez(saveto, train_err=train_err,\n",
    "                    valid_err=valid_err, test_err=test_err,\n",
    "                    history_errs=history_errs, **best_p)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('The code run for %d epochs, with %f sec/epochs' % (\n",
    "        (eidx + 1), (end_time - start_time) / (1. * (eidx + 1))))\n",
    "    print( ('Training took %.1fs' %\n",
    "            (end_time - start_time)), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-12 17:07:52,817 : INFO : loading Word2Vec object from ../data/gensim/imdb_gensim_w2vmodel\n",
      "2018-07-12 17:07:54,807 : INFO : loading vocabulary recursively from ../data/gensim/imdb_gensim_w2vmodel.vocabulary.* with mmap=None\n",
      "2018-07-12 17:07:54,809 : INFO : loading wv recursively from ../data/gensim/imdb_gensim_w2vmodel.wv.* with mmap=None\n",
      "2018-07-12 17:07:54,811 : INFO : loading vectors from ../data/gensim/imdb_gensim_w2vmodel.wv.vectors.npy with mmap=None\n",
      "2018-07-12 17:07:54,893 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-07-12 17:07:54,896 : INFO : loading trainables recursively from ../data/gensim/imdb_gensim_w2vmodel.trainables.* with mmap=None\n",
      "2018-07-12 17:07:54,897 : INFO : loading syn1neg from ../data/gensim/imdb_gensim_w2vmodel.trainables.syn1neg.npy with mmap=None\n",
      "2018-07-12 17:07:54,965 : INFO : setting ignored attribute cum_table to None\n",
      "2018-07-12 17:07:54,967 : INFO : loaded ../data/gensim/imdb_gensim_w2vmodel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model\n",
      "Optimization\n",
      "23750 train examples\n",
      "1250 valid examples\n",
      "25000 test examples\n",
      "Epoch 1/2 Update 10/37 Cost 0.6955891929111729\n",
      "Progress: 0.2min / 1.2min (14%)\n",
      "Epoch 1/2 Update 20/37 Cost 0.6826609284409921\n",
      "Progress: 0.3min / 1.2min (27%)\n",
      "Epoch 1/2 Update 30/37 Cost 0.6888432154371318\n",
      "Progress: 0.5min / 1.2min (41%)\n",
      "Validating.\n"
     ]
    }
   ],
   "source": [
    "train_model(encoder='lstm', gensim_Wemb=True, dim_proj=128, n_words=5000, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_tr, ax_tr = plt.subplots(1, 2, figsize=(16, 4))\n",
    "fig_tr.suptitle(\"Cost and Accuracy on Training Set\")\n",
    "\n",
    "ax_tr[0].plot(train_costs, '-r')\n",
    "ax_tr[0].set_xlabel('Iterations')\n",
    "ax_tr[0].set_ylabel('Cost')\n",
    "\n",
    "ax_tr[1].plot(train_accus, '-g')\n",
    "ax_tr[1].set_xlabel('Iterations')\n",
    "ax_tr[1].set_ylabel('Accuracy')\n",
    "\n",
    "fig_tr.subplots_adjust(wspace=.4)\n",
    "plt.show()\n",
    "\n",
    "fig_v, ax_v = plt.subplots(1, 2, figsize=(16, 4))\n",
    "fig_v.suptitle(\"Validation and test error rates\")\n",
    "\n",
    "ax_v[0].plot(numpy.array(history_errs)[:,0], '-r')\n",
    "ax_v[0].set_xlabel('Iterations')\n",
    "ax_v[0].set_ylabel('Validation error rate')\n",
    "\n",
    "ax_v[1].plot(numpy.array(history_errs)[:,1], '-g')\n",
    "ax_v[1].set_xlabel('Iterations')\n",
    "ax_v[1].set_ylabel('Test error rate')\n",
    "\n",
    "fig_v.subplots_adjust(wspace=.4)\n",
    "plt.show()\n",
    "fig_tr.savefig('../trained_models/Method1_and_2/method2_cost_and_accuracy.png')\n",
    "fig_v.savefig('../trained_models/Method1_and_2/method2_validation_and_error_rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
