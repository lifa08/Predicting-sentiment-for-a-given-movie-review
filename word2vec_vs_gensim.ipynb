{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring two word2vec models (word2vec vs gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word2vec\n",
    "import numpy\n",
    "\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Python interface to Google word2vec\n",
    "\n",
    "Ref: https://github.com/danielfrg/word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    \"\"\"Read a dataset, where the first column contains a real-valued score,\n",
    "    followed by a tab and a string of words.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line_parts = line.strip().split(\"\\t\")\n",
    "            dataset.append((float(line_parts[0]), line_parts[1].lower()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/lifa08/Local_documents/Machine_Learning/Miniproject_test/train.txt'\n",
    "sentences_train = read_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('sentence_forword2vector.txt', 'w')\n",
    "for label, sentence in sentences_train:\n",
    "    f.write(sentence)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2phrase groups up similar words \"Los Angeles\" to \"Los_Angeles\".\n",
    "\n",
    "**Note:** word2phrase will create a phrases text file which can be used as a better input for word2vec. However, we can also use the original text file as input for word2vec, thus this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file sentence_forword2vector.txt\n",
      "Words processed: 100K     Vocab size: 76K  \n",
      "Vocab size (unigrams + bigrams): 51508\n",
      "Words in train file: 133711\n",
      "Words written: 100K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase('sentence_forword2vector.txt', 'sentence_phrases.txt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the word2phrase output.\n",
    "\n",
    "word2vec generates a bin file containing the word vectors in a binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file sentence_phrases.txt\n",
      "Vocab size: 3062\n",
      "Words in train file: 110763\n"
     ]
    }
   ],
   "source": [
    "word2vec.word2vec('sentence_phrases.txt', 'sentence_phrases_bin.bin', size=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2clusters cluster the trained vectors.\n",
    "\n",
    "The output file contains the cluster for every word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file sentence_phrases_bin.bin\n",
      "Vocab size: 9\n",
      "Words in train file: 7295\n"
     ]
    }
   ],
   "source": [
    "word2vec.word2clusters('sentence_phrases_bin.bin', 'sentence_phrases_clusters.txt', 100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lifa08/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2168: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ret = sqrt(sqnorm)\n",
      "/Users/lifa08/anaconda3/lib/python3.6/site-packages/word2vec/utils.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (1.0 / LA.norm(vec, ord=2)) * vec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['</s>', ',', 'the', ..., 'ethnic', 'nonsense', 'earth'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.load('sentence_phrases_bin.bin')\n",
    "model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.58986646e-13,   7.27593387e-13,  -6.30599360e-13, ...,\n",
       "          2.50888205e-13,   5.03685635e-13,   3.18791556e-14],\n",
       "       [             nan,              nan,              nan, ...,\n",
       "                     nan,              nan,              nan],\n",
       "       [ -1.75078571e-01,  -3.41962308e-01,   1.35473743e-01, ...,\n",
       "         -1.93995610e-02,  -2.25419521e-01,  -2.85199702e-01],\n",
       "       ..., \n",
       "       [             nan,              nan,              nan, ...,\n",
       "                     nan,              nan,              nan],\n",
       "       [  8.89440253e-03,  -5.86260185e-02,   1.92473996e-02, ...,\n",
       "          3.45590040e-02,  -2.70427559e-02,  -6.95693418e-02],\n",
       "       [             nan,              nan,              nan, ...,\n",
       "                     nan,              nan,              nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreive the vector of individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['nonsense'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[','][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do simple queries to retreive words similar to \"the\" based on cosine similarity.\n",
    "\n",
    "This returned a tuple with 2 items:\n",
    "\n",
    "    indexes: numpy array with the indexes of the similar words in the vocabulary\n",
    "    metrics: numpy array with cosine similarity to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1016, 1025, 1024, 1023, 1022, 1021, 1020, 1019, 1018, 1017]),\n",
       " array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine(',')\n",
    "indexes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['faith', 'writer', 'class', 'ultimate', 'cute', 'fears', 'fit',\n",
       "       '.nothing', 'steven', 'several'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([('faith',  nan), ('writer',  nan), ('class',  nan),\n",
       "           ('ultimate',  nan), ('cute',  nan), ('fears',  nan),\n",
       "           ('fit',  nan), ('.nothing',  nan), ('steven',  nan),\n",
       "           ('several',  nan)], \n",
       "          dtype=[('word', '<U78'), ('metric', '<f8')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('faith', nan),\n",
       " ('writer', nan),\n",
       " ('class', nan),\n",
       " ('ultimate', nan),\n",
       " ('cute', nan),\n",
       " ('fears', nan),\n",
       " ('fit', nan),\n",
       " ('.nothing', nan),\n",
       " ('steven', nan),\n",
       " ('several', nan)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blood', nan),\n",
       " (\"._'a\", nan),\n",
       " ('let', nan),\n",
       " ('flicks', nan),\n",
       " ('fare', nan),\n",
       " ('.is', nan),\n",
       " ('open', nan),\n",
       " ('aspects', nan),\n",
       " ('sequence', nan),\n",
       " ('low-key', nan)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('good')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gensim word2vec model\n",
    "\n",
    "Refs:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "https://rare-technologies.com/word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_train = read_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.69444, \"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\"), (0.83333, \"the gorgeously elaborate continuation of `` the lord of the rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director peter jackson 's expanded vision of j.r.r. tolkien 's middle-earth .\")]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\", \"the gorgeously elaborate continuation of `` the lord of the rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director peter jackson 's expanded vision of j.r.r. tolkien 's middle-earth .\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "i = 0\n",
    "for label, sentence in sentences_train:\n",
    "    sentences.append(sentence)\n",
    "\n",
    "print(sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], ['the', 'gorgeously', 'elaborate', 'continuation', 'of', '``', 'the', 'lord', 'of', 'the', 'rings', \"''\", 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'can', 'not', 'adequately', 'describe', 'co-writer\\\\/director', 'peter', 'jackson', \"'s\", 'expanded', 'vision', 'of', 'j.r.r', '.', 'tolkien', \"'s\", 'middle-earth', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "print(tokenized_sentences[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "`gensim.models.Word2Vec(sentences, iter)` will run **two passes** over the sentences \n",
    "iterator (or, in general iter+1 passes; default iter=5). \n",
    "\n",
    "First pass: collects words and their frequencies to build **an internal dictionary tree**\n",
    "\n",
    "The second and subsequent passes: train the neural model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-07 11:57:05,037 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-07-07 11:57:05,040 : INFO : collecting all words and their counts\n",
      "2018-07-07 11:57:05,043 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-07-07 11:57:05,046 : INFO : collected 100 word types from a corpus of 140 raw words and 5 sentences\n",
      "2018-07-07 11:57:05,050 : INFO : Loading a fresh vocabulary\n",
      "2018-07-07 11:57:05,054 : INFO : min_count=1 retains 100 unique words (100% of original 100, drops 0)\n",
      "2018-07-07 11:57:05,056 : INFO : min_count=1 leaves 140 word corpus (100% of original 140, drops 0)\n",
      "2018-07-07 11:57:05,059 : INFO : deleting the raw counts dictionary of 100 items\n",
      "2018-07-07 11:57:05,065 : INFO : sample=0.001 downsamples 100 most-common words\n",
      "2018-07-07 11:57:05,070 : INFO : downsampling leaves estimated 55 word corpus (40.0% of prior 140)\n",
      "2018-07-07 11:57:05,073 : INFO : estimated required memory for 100 words and 10 dimensions: 58000 bytes\n",
      "2018-07-07 11:57:05,076 : INFO : resetting layer weights\n",
      "2018-07-07 11:57:05,082 : INFO : training model with 4 workers on 100 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-07-07 11:57:05,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-07-07 11:57:05,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-07 11:57:05,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-07 11:57:05,098 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-07 11:57:05,114 : INFO : training on 700 raw words (268 effective words) took 0.0s, 9625 effective words/s\n",
      "2018-07-07 11:57:05,120 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 10\n",
    "model = gensim.models.Word2Vec(tokenized_sentences[0:5], min_count=1, size=embedding_size, window=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the word vector for an individual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04527435, -0.01737068,  0.04638617, -0.04020905, -0.04004258,\n",
       "       -0.03544782, -0.00919336,  0.03392975,  0.04286923, -0.02652049], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['but']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-07 11:57:05,154 : INFO : saving Word2Vec object under mygword2vmodel, separately None\n",
      "2018-07-07 11:57:05,167 : INFO : not storing attribute syn0norm\n",
      "2018-07-07 11:57:05,174 : INFO : not storing attribute cum_table\n",
      "2018-07-07 11:57:05,193 : INFO : saved mygword2vmodel\n"
     ]
    }
   ],
   "source": [
    "model.save('mygword2vmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-07 11:57:05,264 : INFO : loading Word2Vec object from mygword2vmodel\n",
      "2018-07-07 11:57:05,290 : INFO : loading wv recursively from mygword2vmodel.wv.* with mmap=None\n",
      "2018-07-07 11:57:05,300 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-07-07 11:57:05,306 : INFO : setting ignored attribute cum_table to None\n",
      "2018-07-07 11:57:05,311 : INFO : loaded mygword2vmodel\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('mygword2vmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04527435, -0.01737068,  0.04638617, -0.04020905, -0.04004258,\n",
       "       -0.03544782, -0.00919336,  0.03392975,  0.04286923, -0.02652049], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['but']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.wv` is a dictionary that contains `model.wv.index2word` and `model.wv.syn0`.\n",
    "\n",
    "`model.wv.syn0` contains the word embeddings and is thus of shape (num_words, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04527435 -0.01737068  0.04638617 -0.04020905 -0.04004258 -0.03544782\n",
      " -0.00919336  0.03392975  0.04286923 -0.02652049]\n",
      "(100, 10)\n",
      "[[-0.0092307   0.01956238  0.01146896  0.04565843 -0.00327957 -0.03220305\n",
      "  -0.04059184 -0.04343898 -0.00902533  0.03680716]\n",
      " [-0.0008527   0.04095223 -0.03789742 -0.04003941 -0.01954055 -0.03402293\n",
      "   0.01164207 -0.01927962 -0.01874233  0.04072549]\n",
      " [ 0.00829409  0.00988619 -0.03435677  0.02545083 -0.04681684  0.03951706\n",
      "  -0.00840738  0.03969266  0.03700726 -0.01092675]]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary that maps words to their corresponding embedding vectors\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "print(w2v['but'])\n",
    "print(model.wv.syn0.shape)\n",
    "print(model.wv.syn0[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0092307   0.01956238  0.01146896  0.04565843 -0.00327957 -0.03220305\n",
      "  -0.04059184 -0.04343898 -0.00902533  0.03680716]\n",
      " [-0.0008527   0.04095223 -0.03789742 -0.04003941 -0.01954055 -0.03402293\n",
      "   0.01164207 -0.01927962 -0.01874233  0.04072549]\n",
      " [ 0.00829409  0.00988619 -0.03435677  0.02545083 -0.04681684  0.03951706\n",
      "  -0.00840738  0.03969266  0.03700726 -0.01092675]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/\n",
    "embedding_matrix = numpy.zeros((len(model.wv.vocab), embedding_size))\n",
    "for i in range(len(model.wv.vocab)):\n",
    "    embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix[:3])\n",
    "\n",
    "print(numpy.allclose(embedding_matrix, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer sentence words to their corresponding embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0092307   0.01956238  0.01146896  0.04565843 -0.00327957 -0.03220305\n",
      "  -0.04059184 -0.04343898 -0.00902533  0.03680716]\n",
      " [ 0.02223633 -0.04034107 -0.00503555  0.04257284  0.01365479  0.04847161\n",
      "  -0.01993341 -0.03781372 -0.04177392  0.02818117]]\n",
      "[[-0.0092307   0.01956238  0.01146896  0.04565843 -0.00327957 -0.03220305\n",
      "  -0.04059184 -0.04343898 -0.00902533  0.03680716]\n",
      " [ 0.02223633 -0.04034107 -0.00503555  0.04257284  0.01365479  0.04847161\n",
      "  -0.01993341 -0.03781372 -0.04177392  0.02818117]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sentence_matrix = numpy.zeros((len(tokenized_sentences[0]), embedding_size))\n",
    "for i, word in enumerate(tokenized_sentences[0]):\n",
    "    sentence_matrix[i] = model.wv[word]\n",
    "    # sentence_matrix[i] = w2v[word]\n",
    "print(sentence_matrix[:2])\n",
    "\n",
    "sentence_wv = model.wv[tokenized_sentences[0]]\n",
    "print(sentence_wv[:2])\n",
    "\n",
    "print(numpy.allclose(sentence_matrix, sentence_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[  0.  13.   6.  14.   7.  15.   0.  16.  17.   4.  18.   8.  19.   9.  20.\n",
      "  10.  21.   4.  22.   7.  23.   3.  24.  25.  26.  27.  28.  29.   5.  30.\n",
      "  31.  32.  33.  34.  35.   2.]\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.vocab))\n",
    "\n",
    "idx_sentence = numpy.zeros(len(tokenized_sentences[0]))\n",
    "for i, word in enumerate(tokenized_sentences[0]):\n",
    "    idx_sentence[i] = model.wv.vocab[word].index\n",
    "print(idx_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01843417, -0.00773418,  0.02616785, -0.04447961,  0.02029118,\n",
       "       -0.01890256,  0.03755583, -0.00378606, -0.00943715,  0.04591386])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7161\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_idxs(tokenized_sentences):\n",
    "    idx_sentences = []\n",
    "    for tokenized_sentence in tokenized_sentences:\n",
    "        idx_one_sentence = numpy.zeros(len(tokenized_sentence))\n",
    "        idx = 0\n",
    "        for idx, word in enumerate(tokenized_sentence):\n",
    "            idx_one_sentence[idx] = model.wv.vocab[word].index\n",
    "        idx_sentences.append(idx_one_sentence) \n",
    "    return idx_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  0.,  13.,   6.,  14.,   7.,  15.,   0.,  16.,  17.,   4.,  18.,\n",
      "         8.,  19.,   9.,  20.,  10.,  21.,   4.,  22.,   7.,  23.,   3.,\n",
      "        24.,  25.,  26.,  27.,  28.,  29.,   5.,  30.,  31.,  32.,  33.,\n",
      "        34.,  35.,   2.]), array([  0.,  36.,  37.,  38.,   1.,   8.,   0.,  39.,   1.,   0.,  40.,\n",
      "         9.,  41.,   6.,  42.,  43.,  10.,   3.,  44.,   1.,  45.,  46.,\n",
      "        47.,  48.,  49.,  50.,  51.,  52.,   4.,  53.,  54.,   1.,  55.,\n",
      "         2.,  56.,   4.,  57.,   2.]), array([ 58.,  59.,  60.,  61.,   3.,  62.,   1.,  63.,  11.,   3.,  12.,\n",
      "        64.,  65.,   5.,   3.,  12.,  66.,  67.,  68.,   7.,   0.,  69.,\n",
      "        11.,  70.,   0.,  71.,  72.,  73.,  74.,   0.,  75.,   5.,  76.,\n",
      "         5.,  77.,   1.,   0.,  78.,   2.]), array([ 79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,   1.,\n",
      "        89.,  90.,  91.,  92.,  93.,   1.,  94.,   2.]), array([ 95.,   0.,  96.,   6.,  97.,  98.,  99.,   2.])]\n"
     ]
    }
   ],
   "source": [
    "idx_sentences = sentences_to_idxs(tokenized_sentences[0:5])\n",
    "print(idx_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec model does not need to tokenize sentence before training while gensim model expects a sequence of sentences which are composed of a list of words. Therefore, gensim model is often used together with natural language processing tools such as nltk. From the above explorations, we can see that gensim model is more stable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
